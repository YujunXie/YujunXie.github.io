---
title: 机器学习(3):代价函数
key: 20170910
tags: 机器学习
---

代价函数在不同的书和视频上都可能有不同的叫法，比如损失函数，目标函数等等。

在我看来，**代价函数**=**损失函数**，而**目标函数**作为一种概念，将代价函数视为一个目标，通过梯度下降，正规方程等方法求得代价函数最小化下的所需参数。

代价函数可以有多种表达方式，如：

`L(Y,f(X)) = (Y-f(X)).^2`

`L(Y,f(X)) = |Y-f(X)|`

`L(Y,f(X)) = -log(p(Y|X))`

...

可以看出，代价函数的值就是数据真值与预测值拟合程度的大小。损失函数越小，拟合程度越大，模型就越好。

那么代价函数是怎么具体来表示的呢？
首先，我们有一堆数据`X(n),Y(n)`，把它们放在坐标内。

这时候，我们需要用一条线（直线或是曲线）用来拟合这些数据。如果这条线我们用带两个参数的假设函数来表示：

![hypothesis.jpg](https://i.loli.net/2018/08/20/5b7a5f6c7a06b.jpg)


<!--more-->


如何使这条线最大程度地拟合所有的数据？这就需要确定函数中的两个参数`theta1`,`theta2`。
（参数的个数是不确定的，参数越多，代价函数的最小化就越复杂）

这样就产生了以求得含最佳参数的假设函数的代价函数：

![costFunc.jpg](https://i.loli.net/2018/08/20/5b7a5f763f393.jpg)

（取方差再除以1/2是为了减少个别波动数据的影响）

因此，我们的目标就是***min(J)***

但是代价函数并不是越小越好，这就涉及到经验风险最小化和结构风险最小化的思想，因此延伸出了`欠拟合`，`过拟合`，`正则化`，`泛化能力`等方法和概念。

一般的，在最小化代价函数J的过程中，我们根据theta的改变绘制出代价函数J的二维坐标图如下：

![J1.png](https://i.loli.net/2018/08/20/5b7a5f764094a.png)

当 J = 0 时，theta就取到了合适的值。

还有一种图用来绘制代价函数，从而能清楚的看到代价函数J是如何收敛到最小点的，叫做轮廓图(Contour plot)：

![J2.png](https://i.loli.net/2018/08/20/5b7a5f6c864f1.png)

可以看到当 J值 所对应的点到达最内环的椭圆中心时，theta取到了合适的值。
