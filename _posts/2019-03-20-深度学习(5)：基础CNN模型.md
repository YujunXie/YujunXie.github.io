---
title: 深度学习(5)：基础CNN模型
key: 20190320
tags: 深度学习
---

- [LeNet5](#LeNet5)
- [AlexNet](#AlexNet)
- [VGG](#VGG)
- [GoogleNet](#GoogleNet)
- [ResNet](#ResNet)
- [DenseNet](#DenseNet)

LeNet5
---
网络结构：
![lenet.png](https://i.loli.net/2019/03/20/5c919cde387e9.png)

input->conv1->pool1->conv2->pool2->fc1->fc2->output(softmax分类)

是一种用于手写体字符识别的非常高效的卷积神经网络。

AlexNet
---
网络结构：![alexnet.png](https://i.loli.net/2019/03/20/5c919d26e8e8c.png)

闪光点：
- 更深的网络：共包含5层卷积层和三层全连接层，最终softmax输出是1000类。
- 数据增广：对256×256的图像进行随机裁剪，得到尺寸为3×224×224的图像。（增加模型泛化能力，避免过拟合）
- ReLU：代替Sigmoid来加快SGD的收敛速度。
- dropout：缓解模型的过拟合。
- LRN（局部响应归一层）：不太重要

使用了多GPU加速训练。

VGG
---
网络结构：
![vgg.png](https://i.loli.net/2019/03/20/5c919ecdcbf4c.png)

为了解决初始化（权重初始化）等问题，VGG采用的是一种Pre-training的方式，就是先训练一部分小网络，然后再确保这部分网络稳定之后，再在这基础上逐渐加深。上图从左到右体现的就是这个过程，并且当网络处于D阶段的时候，效果是最优的，因此D阶段的网络也就是VGG-16。VGG-16的16指的是conv+fc的总层数是16，是不包括max pool的层数。

VGG-16网络结构：
![vgg16.png](https://i.loli.net/2019/03/20/5c919ecdd1a21.png)

VGG-16的结构非常整洁，深度较AlexNet深得多，里面包含多个conv->conv->max_pool这类的结构,VGG的卷积层都是same的卷积，即卷积过后的输出图像的尺寸与输入是一致的。

闪光点：
- 卷积层使用更小的filter尺寸和间隔，如1x1,3x3

1. 3×3卷积核的优点：
  
  多个3×3的卷积层比一个大尺寸filter卷积层有更多的非线性，使得判决函数更加具有判决性。
  
  多个3×3的卷积层比一个大尺寸的filter有更少的参数，假设卷基层的输入和输出的特征图大小相同为C，那么三个3×3的卷积层参数个数3×（3×3×C×C）=27CC；一个7×7的卷积层参数为49CC；所以可以把三个3×3的filter看成是一个7×7filter的分解（中间层有非线性的分解）。

2. 1*1卷积核的优点：
  
  作用是在不影响输入输出维数的情况下，对输入进行线性形变，然后通过Relu进行非线性处理，**增加网络的非线性表达能力**。

GoogleNet
---
GoogleNet在加深网络的同时（22层），也在网络结构上做了创新，引入Inception结构代替了单纯的卷积+激活的传统操作（这思路最早由Network in Network提出）。

闪光点：
- 引入Inception结构。
- 中间层的3个辅助LOSS单元：目的是计算损失时让低层的特征也有很好的区分能力，从而让网络更好地被训练，收敛。在论文中，这两个辅助LOSS单元的计算被乘以0.3，然后和最后的LOSS相加作为最终的损失函数来训练网络。
- 后面的3个全连接层全部替换为简单的全局平均pooling：在最后参数会变的更少。而在AlexNet中最后3层的全连接层参数差不多占总参数的90%，使用大网络在宽度和深度允许GoogleNet移除全连接层，但并不会影响到结果的精度。

- Inceptionv1结构：
![googlenet](https://i.loli.net/2019/03/20/5c91a104acf4b.png)

Inception结构里主要做了两件事：

1. 通过3×3的池化、以及1×1、3×3和5×5这三种不同尺度的卷积核，一共4种方式对输入的特征响应图做了特征提取。通过concatenation操作把4组不同类型但大小相同的特征响应图一张张并排叠起来，形成新的特征响应图.
2. 为了降低计算量。同时让信息通过更少的连接传递以达到更加稀疏的特性，采用1×1卷积核来实现多通道输入的**降维**。

- inception V2

其实在网络上没有什么改动，只是在输入的时候增加了batch normalization，训练起来收敛更快，学习起来自然更高效，可以减少dropout的使用。 
进行了归一化：保证出现过的最大值为1，最小值为0，所有输出保证在0~1之间。

- inception V3
把googlenet里一些7x7的卷积变成了1x7和7x1的两层串联，3x3的也一样，变成了1x3和3x1，这样加速了计算，还增加了网络的非线性，减小过拟合的概率。另外，网络的输入从224改成了299.
- inception v4
实际上是把原来的inception加上了resnet的方法，从一个节点能够跳过一些节点直接连入之后的一些节点，并且残差也跟着过去一个。用来提高速度的。另外就是V4把一个先1x1再3x3那步换成了先3x3再1x1.

ResNet
---
网络结构：
![resnet.jpg](https://i.loli.net/2019/03/20/5c91a333c4833.jpg)

闪光点：
- 层数非常深，已经超过百层：容易产生梯度消失和网络的退化问题（即增加网络层数却导致更大的训练误差）。
- 引入残差单元来解决退化问题：允许我们训练更深的网络。

残差单元(shortcut)：
![r](https://i.loli.net/2019/03/20/5c91a333cf2ee.png)

x为输入，H(x)为输出，F(x)=H(x)-x表示残差。将残差F(x)作为优化目标。通过直接将输入信息绕道传到输出，保护信息的完整性，整个网络只需要学习输入、输出差别的那一部分，简化学习目标和难度。

考虑到x的维度与F(X)维度可能不匹配情况，需进行维度匹配。提出了下面两种方法：

1. zero_padding:对恒等层进行0填充的方式将维度补充完整。这种方法不会增加额外的参数
2. projection:在恒等层采用1x1的卷积核来增加维度。这种方法会增加额外的参数

两种形态的残差模块：
![s](https://i.loli.net/2019/03/20/5c91a333d5634.png)

左图是常规残差模块，有两个3×3卷积核卷积核组成，但是随着网络进一步加深，这种残差结构在实践中并不是十分有效。针对这问题，右图的“瓶颈残差模块”（bottleneck residual block）可以有更好的效果，它依次由1×1、3×3、1×1这三个卷积层堆积而成，这里的1×1的卷积能够起降维或升维的作用，从而令3×3的卷积可以在相对较低维度的输入上进行，以达到提高计算效率的目的。

ResNet有不同的网络层数，比较常用的是50-layer，101-layer，152-layer。他们都是由上述的残差模块堆叠在一起实现的。

DenseNet
---
DenseNet吸收了ResNet最精华的部分，并在此上做了更加创新的工作，使得网络性能进一步提升。

闪光点：
- 密集连接：缓解梯度消失问题，加强特征传播，鼓励特征复用，极大的减少了参数量。

DenseNet是一种具有密集连接的卷积神经网络。在该网络中，任何两层之间都有直接的连接，也就是说，网络每一层的输入都是前面所有层输出的并集，而该层所学习的特征图也会被直接传给其后面所有层作为输入。下图是 DenseNet 的一个`dense block`示意图，一个block里面的结构如下，与ResNet中的BottleNeck基本一致：`BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3)` ，而一个DenseNet则由多个这种block组成。每个DenseBlock的之间层称为`transition layers`，由`BN−>Conv(1×1)−>averagePooling(2×2)`组成。
![denseblock](https://i.loli.net/2019/03/20/5c91a66439387.png)

缺点：恐怖的内存占用

