---
title: 深度学习(1):是什么？
key: 20171122
tags: 深度学习
---

很多人搞不清楚人工智能，机器学习和深度学习三者之间的关系，没关系，放一张图你就明白了：

![Deep_Learning_Icons_R5_PNG.jpg.png](https://i.loli.net/2018/08/20/5b7a72f2b5b0e.png)

**人工智能**的范畴最广，它包含一切赋予机器智能的思想与技术。人工智能又分为强人工智能和弱人工智能。强人工智能General AI 与弱人工智能Narrow AI 都有真正推理和解决问题的能力，区别是机器是否有知觉，有自我意识。而前者几乎不可能实现。现在的人工智能只能处理特定的技术，如人脸识别，图像分类，情感分析等等。

**机器学习**是一种实现人工智能的方法，是使用算法来解析数据，从中学习，然后对真实世界中的事件做出决策和预测。

而**深度学习**又是实现机器学习的一种方法，它依托于多层神经网络，拥有多个参数，学习能力大大提升（“深度”指的就是神经网络的层数）。

> 深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。

<!--more-->

深度学习与2006年Hinton提出，崛起于2012年的ImageNet挑战大赛。当年Hinton实验室的Alex等人借助GPU强大的计算能力，使用了一个多层的卷积神经网络，加上一些优化技巧和策略，将图像分类的准确率从74% 一下提升到84.7%。

深度学习扒开来看就是**多层神经网络**，而神经网络在很久之前就被提出来了，但是一直被支持向量机压的死死的，原因是跟不上的计算能力，规模太小的数据和蹩脚的优化技巧。

深度学习是一种端到端的模型，输入层-> 隐藏层 -> 输出层，我们关心的就是输出能得到什么，而中间的隐藏层就像一个黑盒，十分隐蔽复杂，每一层都可以为了最终的任务来调整自己，最终实现各层之间的合作，自主学习输入的数据中抽象的特征并输出我们想要的结果。

> 深度学习就是一种特征学习方法，把原始数据通过一些简单的但是非线性的模型转变成为更高层次的，更加抽象的表达。通过足够多的转换的组合，非常复杂的函数也可以被学习。对于分类任务，高层次的表达能够强化输入数据的区分能力方面，同时削弱不相关因素。比如，一副图像的原始格式是一个像素数组，那么在第一层上的学习特征表达通常指的是在图像的特定位置和方向上有没有边的存在。第二层通常会根据那些边的某些排放而来检测图案，这时候会忽略掉一些边上的一些小的干扰。第三层或许会把那些图案进行组合，从而使其对应于熟悉目标的某部分。随后的一些层会将这些部分再组合，从而构成待检测目标。深度学习的核心方面是，上述各层的特征都不是利用人工工程来设计的，而是使用一种通用的学习过程从数据中学到的。

![representation.jpg](https://i.loli.net/2018/08/20/5b7a72f1d92b8.jpg)

附上一图，加深理解。

----------

深度学习的**应用领域**

 1. 语音识别

 2. 自然语言处理
如文本理解，情感分析等。

 3. 计算机视觉
如图像分类，人脸识别，目标检测， 图像分割，行为分析等等。

---

深度学习中的**深度神经网络**(DNN)

 - **全连接神经网络**

最“简单”的多层神经网络。

![full.jpg](https://i.loli.net/2018/08/20/5b7a72f248c5f.jpg)

相邻层的每个节点之间相连，因此网络的参数很多，计算量比较大，训练速度太慢。大多数情况下不使用全连接层，一方面考虑的是训练速度，一方面是输出的结果并不需要某些节点间的连接（计算），相当于多余的连接。

早期的全连接神经网络，就是属于用于对提取的特征进行分类的模块。

 - **卷积神经网络**CNN

基本结构包括两层：特征提取层和特征映射层。

即INPUT（输入层）-> CONV（卷积层）-> RELU（激活函数）-> POOL（池化层）-> FC（全连接层）。

其中卷积层用于特征提取，越深的卷积神经网络会提取越具体的特征，越浅的网络提取越浅显的特征。

池化层和全连接层用于特征映射，来自其他层的输入在这里被平化和发送，以便将输出转换为网络所需的参数。

![cnn.jpg](https://i.loli.net/2018/08/20/5b7a72f246b77.jpg)

CNN 除了包含执行目标识别任务的 AlexNet 等深度卷积网络，还包括很多优秀的模型用于处理目标检测、语义分割和超分辨率等任务，如VGGNet,GooleNet,ResNet等。它们以不同的方式应用卷积过程处理不同的任务，并在这些任务上产生了非常好的效果。

 - **递归神经网络**RNN

可以让神经网络处理诸如文本、音频和视频等序列数据。它们可用来做序列的高层语义理解、序列标记，甚至可以从一个片段生产新的序列。

基本的 RNN 结构难以处理长序列，然而一种特殊的 RNN 变种即「长短时记忆（LSTM）」网络可以很好地处理长序列问题。

![rnn.jpg](https://i.loli.net/2018/08/20/5b7a72f1d76b6.jpg)

还有一些无监督学习的模型没介绍到的，放一张图：

![DL.jpg](https://i.loli.net/2018/08/20/5b7a72f24a75b.jpg)
