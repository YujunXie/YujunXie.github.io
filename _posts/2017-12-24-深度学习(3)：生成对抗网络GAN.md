---
title: 深度学习(3)：生成对抗网络GAN
key: 20171224
tags: 深度学习 GAN
---

生成对抗网络（Generative Adversarial Nets）最早是在2014年的时候由蒙特利尔大学的AI学者 Ian Goodfellow提出的，被引入深度学习领域。其主要思想是二人博弈，双方通过对方的表现来调整提升自己的能力，最终达到共同进步的目的。

 - 基本概念

GAN中有两个网络，一个用于生成数据，称为生成器（generator），一个用于判别数据真假，称为判别器(discriminator)。

![gan.png](https://i.loli.net/2018/08/22/5b7cf4648d486.png)

![gans.png](https://i.loli.net/2018/08/22/5b7cf4645aed9.png)

生成器G接收一个随机噪声z生成图片G(z)；

判别器D判别图片是真实的还是虚假的（合成），D(x)=0 代表图片为假，D(x)=1 代表图片为真；

G生成的数据传给D判别，得到的结果又传回G。在训练过程中，G的目标是生成判别器D难以区分的图片，D的目标是尽量将G生成的图片与真实图片区分开来，这样就构成了一个动态的“博弈”过程。

最终目标为G生成的图片D难辨真假，即D(x)=0.5，最终得到的成熟的生成对抗网络能够生成大量以假乱真的数据。

<!--more-->

 - 理论实现

1. 公式
	
	`G(z; θg)`, `D(x; θd)`
	
	`px`：真实数据集的分布
	
	`pg`：伪数据x的分布
	
	`pz`：输入噪声先验概率
	
	二元极大极小博弈：
	
	![屏幕快照 2017-12-24 15.09.16.png](https://i.loli.net/2018/08/22/5b7cf81308bbd.png)
	
	`max D`: 训练D使其为训练集和G生成的样本分配正确标签的概率增大。`Min log(D(x))`
	`min G`: 训练G使D失误的概率增大，即判别G生成的样本为真的概率D(G(z))增大。`Min log(1-D(G(z))) `

2. 算法

	为了防止在有限数据集上发生过拟合的现象，选择k次D的优化+一次G的优化。这样G变化地不会太快，D也能在每次G的优化后通过优化到达最优解。
	
	![2.png](https://i.loli.net/2018/08/22/5b7cf46490858.png)
	
	> 第一步训练D，D是希望V(G,D)越大越好，所以加上梯度(ascending)。
	> 
	> 第二步训练G，G是希望V(G,D)越小越好，所以减去梯度(descending)。
	> 
	> 先将G拼接在D的上方，即G的输出作为D的输入，同时固定D的参数，并将进入G的噪音样本标签全部改成“1”，为了最小化损失函数，此时只能改变G的每一层权重，反复迭代后，G的生成能力得到改进。
	
	而且在最初的时候，由于G表现较差，D判别的正确率会非常高，可能导致后续`log(1-D(G(z)))`饱和。所以选择训练`G Max logD(G(z))`而不是 `Min log(1-D(G(z)))`，不会导致太快饱和。

3. 训练过程中的概率分布图

	![3.png](https://i.loli.net/2018/08/22/5b7cf463e12d0.png)
	
	黑点表示`px`（真实数据的真实分布），蓝点表示D判定正确的概率，绿线表示`pg`（生成网络学习到的伪造分布），标x的横线代表服从高斯分布x的采样空间，标z的横线代表服从均匀分布z的采样空间。
	
	可以看到，当`pg = pdata`，对抗网络达到全局最优。且`Dx = 1/2`，即乱猜。

----------

 - 优缺点与应用

1. 优点

	> （1）GAN是更好的生成模型，它可以生成非常清晰的图片，而传统的生成模型生成的图片通常比较模糊。
	
	>（2）模型优化只用到了反向传播，而不需要马尔科夫链式的学习机制，直接进行采样和推断。
	
	>（3）生成模型G的参数更新不是来自于数据样本本身（不是对数据的似然性进行优化），而是来自于判别模型D的一个反传梯度。
	
	>（4）训练时不需要对隐变量做推断。
	
	>（5）各种类型的损失函数都可以整合到GAN模型中。
	
	>（6）GAN可以解决一些传统的机器学习中所面临的数据不足的问题，因此可以应用在半监督学习、无监督学习、多视角、多任务学习等任务中。
	
	>（7）概率密度不可计算时，GAN仍可应用。
	
	>（8）任何一个可微分的函数，都可以用于构建G和D。
	
	>（9）GAN可以与深度神经网络相结合（CNN/RNN）。在实际中，我们可以使用深度卷积网络，来参数化生成模型。另外，GAN和RNN结合在一起，用来处理和描述一些连续的序列数据，可以学习到序列数据的分布，同时也可以产生序列数据应用，包括对音乐数据或者是一些自然语言数据的建模和生成。
	
	>（10）GAN可以应用在强化学习中，提高强化学习的学习效率。

2. 缺点

	> （1）GAN的可解释性非常差。因为我们最后学到的数据分布Pg(G)，没有显示的表达式。它只是一个黑盒子一样的映射函数：输入是一个随机变量，输出是我们想要的一个数据分布。
	> 
	>（2）GAN比较难训练。因为GAN要交替优化两个部件，而这两个部件之间的优化需要很好的同步。例如，在实际中我们常常需要 D 更新K次， G 才能更新1次。如果没有很好地平衡这两个部件的优化，那么G最后就极大可能会坍缩到一个鞍点。
	
	>（3）不收敛，我们使用的优化方法很容易只找到一个局部最优点，而不是全局最优点。例如模式崩塌（Mode Collapse）就是一种无法收敛的情况，对于一个最小最大博弈的问题，我们该把最小（min）还是最大（max）放在内循环？ minmax V(G,D) 不等于 maxmin V(G,D)。如果 maxD 放在内圈，算法可以收敛到应该有的位置，如果 minG 放在内圈，算法就会一股脑地扑向其中一个聚集区，而不会看到全局分布。这样会导致我们的数据生成结果就会少很多多样性，基本上仅会带有部分的几个特征（因为学习出来的特征都只聚集在全部特征中的几个地方）。
	
	>（4）生成模型与源数据拟合之后就没法再继续学习了（因为常数线 y = 1/2 求导永远为 0）。
	
	>（5）找不到一个科学的方法对GAN进行评估。
	
	>（6）到目前为止我们提到的输出或者案例都是连续的情况。如果我们的 G 想要生成离散值，就会遇到一个数学问题：无法微分（differentiate）。所以GAN无法输出离散值。
	
	>（7）GANs 不稳定，有时候它永远不会开始学习，或者生成我们认为合格的输出。模型过于自由。

3. GANs变种

	（1）CGAN
	
	条件生成对抗网络（Conditional GAN）。
	
	在生成模型和判别模型中加入条件y，控制达到我们的预期，而不是随机的噪声分布。条件y是标签或不同模态的数据（如图像）。
	
	![4.jpg](https://i.loli.net/2018/08/22/5b7cf462d881a.jpg)
	
	（2）DCGAN
	
	将卷积网络CNN运用到非监督学习中的生成对抗网络GAN中，对GAN有一定的结构约束，构建了很好的图像表征，生成器和判别器还能被复用为监督学习中的特征提取器。
	
	![5.png](https://i.loli.net/2018/08/22/5b7cf46382320.png)
	
	（3）LAPGANs
	
	在拉普拉斯金字塔的每一层使用独立的卷积网络CNN生成模型，输出图像作为下一层的输入，从低到高，一系列的CNN通过逐渐增加分辨率连续生成图像，将图像由粗糙变精致。每层的CNN由两部分训练，一个是低分辨率图像，一个是噪声矢量。
	
	![lap1.jpg](https://i.loli.net/2018/08/22/5b7cf463c2319.jpg)
	
	![lap2.jpg](https://i.loli.net/2018/08/22/5b7cf8157ce89.jpg)

4. 应用

	由于生成对抗网络中的生成模型能够生成大量“真实的数据”，GAN主要被用于合成，修复等应用。
	
	图像处理；
	
	![1.png](https://i.loli.net/2018/08/22/5b7cf46469704.png)
	
	有眼镜的男人 - 无眼镜的男人 + 无眼镜的女人 = 有眼镜的女人
	
	（1）SRGAN
	
	使用对抗生成网络实现单张逼真的超分辨率图像，解决SISR问题。
	
	![srgan.png](https://i.loli.net/2018/08/22/5b7cf81655859.png)
	
	（2）文字到图像的合成
	
	探索一种与GAN结合的新架构，使用文本语句合成图像，而不是使用类标签。在基于先前的自然语言描述较为成熟的工作的基础上，目标是建立从字词到图像像素的直接映射。
	
	![6.png](https://i.loli.net/2018/08/22/5b7cf463169c3.png)
	
	声音处理；文字生成；信息破译与信息安全；个性化生成；高精度的样本预测；

----------

参考资料：

[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)

[Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784)

[Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks
](https://arxiv.org/abs/1506.05751)

[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)

[Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802)
